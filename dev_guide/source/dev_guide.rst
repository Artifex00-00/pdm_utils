Introduction
============

This is a developer's guide for the ``pdm_utils`` package. It provides miscellaneous notes regarding the structure of the ``pdm_utils`` source code repository and general guidelines/conventions for maintaining and developing the source code.

Repository structure
--------------------

src/pdm_utils/
**************

All python source code is stored here. This folder is what generates the released ``pdm_utils`` python package and gets installed
by ``pip``.


tests/
******

Unit and integration tests designed for ``pdm_utils``.

misc/
*****

Miscellaneous documentation or reference material for maintaining SEA-PHAGES phage genomics databases on the GitHub repository that should not be included in Sphinx-generated documentation.

legacy/
*******

A compilation of legacy Python2 scripts used to maintain SEA-PHAGES phage genomics databases.

docs/
*****

All source and Sphinx-built files for ``pdm_utils`` documentation that are used for ReadTheDocs.

dev_guide/
**********

Directory of files required for and generated by Sphinx for the developer's guide.


schema/
*****

Empty database schemas for historical reference, as well as SQL scripts to upgrade or downgrade database schemas from one version to another.






Misc. items for PyPI
********************

Several files for, or generated by, ``setuptools`` to generate archives that are uploaded to PyPI:

    - setup.py
    - dist/
    - build/
    - src/pdm_utils.egg-info


requirements.txt
****************

List of Python dependencies installed in the Conda development environment 'pdm_utils-dev', which is used for Sphinx, ReadTheDocs, and PyPI.

environment.yml
****************

List of all Python and non-Python dependencies installed in the Conda development environment 'pdm_utils-dev'.


README.md
*********

General information about the GitHub repository.


LICENSE.txt
***********

``pdm_utils`` license information.



contributors.txt
****************

A list of developers who have contributed to this repository.


change_version.py
****************

Script to change the version number in several locations in the repository at one time.




Dependencies
------------

The Sphinx documentation provides a list of python and binary dependencies to use the package. Additionally, there are several third-party python packages required for development:

    - sphinx
    - sphinx_rtd_theme
    - twine

All python code in the repo can be executed using the following Conda environment 'pdm_utils-dev'. First install Anaconda locally. Then execute the following commands::

    > conda create --name pdm_utils-dev python pip biopython pymysql paramiko sphinx sphinx_rtd_theme twine tabulate curl sqlalchemy
    > conda activate pdm_utils-dev


Here's a list of some of the current software versions used for development:

    - conda 4.5.11
    - mysql  Ver 14.14 Distrib 5.7.24, for osx10.9 (x86_64)
    - Python 3.7.3


To add ``pdm_utils`` module to python's syspath in a shell environment on-the-fly, use the following command, edited so that it points to your local repo::

    > export PYTHONPATH="${PYTHONPATH}:/path/to/pdm_utils/src/"



To create a list of pinned Python and non-Python packages and binaries installed in the conda environment::

    (pdm_utils-dev)> conda env export | grep -v "^prefix: " > environment.yml


To create a list of just the pinned Python packages installed in the conda environment::

    (pdm_utils-dev)> pip freeze > requirements.txt



Running the test suites
-----------------------

The directory of integration and unit tests can be stored completely separately from the actual package directory. However, in order for ``unittest`` to be able to import the ``pdm_utils`` module that needs to be tested, ``unittest`` needs to be run in the directory immediately above the module. Follow the steps below to run the tests.

    1. Navigate to the src directory::

        > cd /path/to/pdm_utils/src/

    2. To run all tests::

        > python3 -m unittest discover ../tests

    3. To run only unit tests or integration tests::

        > python3 -m unittest discover ../tests/unit/
        > python3 -m unittest discover ../tests/integration/

    4. To run tests on only a specific module::

        > python3 -m unittest discover ../tests/integration/ -p test_phamerator.py


For integration tests that require a MySQL database, it is expected that MySQL user 'pdm_anon' exists with password 'pdm_anon' that has all privileges for 'test_db' database. Log in to MySQL as the 'root' user and execute the following commands::

    mysql> CREATE USER 'pdm_anon'@'localhost' IDENTIFIED BY 'pdm_anon';
    mysql> GRANT ALL PRIVILEGES ON test_db.* TO 'pdm_anon'@'localhost';
    mysql> GRANT SELECT ON *.* TO 'pdm_anon'@'localhost';
    mysql> FLUSH PRIVILEGES;








Build Sphinx documentation
--------------------------

For Sphinx to find the entire ``pdm_utils`` package for autodoc, and to NOT autodoc any other python files in the repo (such as tests), the package directory needs to be stored within a directory that contains no other files. So the primary ``pdm_utils`` package directory is stored within 'src', and the sphinx 'config.py' file records that 'src' is where to start autodoc.

    1. Navigate to the docs directory::

        > cd /path/to/pdm_utils/docs/

    2. To initialize autodoc (this does not need to be run every time)::

        > sphinx-apidoc -o ./source/ ../src/pdm_utils/

    3. Build the docs::

        > make clean
        > sphinx-build -b html ./source ./build

    (make build may also be used instead of sphinx-build, not sure though)

This generates a preview of the html documentation. In order to push the updated documentation to ReadTheDocs:

    1. Merge all source code updates into the master git branch.
    2. Push all changes in the master branch to the GitHub repo.
    3. Login to readthedocs.org.
    4. Choose the 'pdm_utils' project.
    5. Choose 'build version'.









Build the PyPI package
----------------------

Follow the steps below to push a new version of the ``pdm_utils`` package to PyPI:

    1. Increment the version number:

        - In the top-level directory, run the following command::

            > python3 ./change_version.py <major, minor, or micro>

        - This updates the version in four separate locations:
            - setup.py (used by PyPI for tracking package versions)
            - src/pdm_utils/__init__.py (can be accessed after installation)
            - docs/conf.py (for Sphinx documentation)
                - version number
                - release number


    .. warning::
        The version number in setup.py must be unique within the ``pdm_utils`` version history in TestPyPI and PyPI databases. Even if the package release is removed from these databases, PyPI stores its version number, and a subsequent package release cannot have the same version number, even if it has been deleted.

    2. By default, the working directory is outside of top-level pdm_utils, but the location can be specified within setup.py using the 'package_dir' and 'packages' parameters. Run the setup script from the working directory::

        > python3 setup.py sdist bdist_wheel


    3. To test the package without uploading to PyPI, install the locally-built package file::

        > pip install /path/to/dist/pdm_utils_XXXX.tar.gz

    4. In a new terminal, open a Python IDE and test the package.

    5. After testing locally, upload the package to TestPyPI::

        > python3 -m twine upload --repository-url https://test.pypi.org/legacy/ dist/*

    6. Open a separate terminal that doesn't utilize the pdm_utils-dev conda environment (for instance, load the pdm_utils-user conda environment), and install the package with pip::

        > python3 -m pip install --index-url https://test.pypi.org/simple/ --no-deps pdm_utils

    7. Now upload the package to PyPI::

        > twine upload ./dist/*




Code conventions
----------------

This repo utilizes the following coding conventions:

    1. Use spaces instead of tabs.
    2. Use 'snake_case' for variables and 'PascalCase' for classes.
    3. Docstrings:

        - for all methods and functions.
        - written in reStructuredText for Sphinx autodoc.

    4. Use double (instead of single) quotes for string literals (although not as important in docstrings and comments)
    5. Tests:

        - should be written for all methods and functions.
        - should be constructed for the ``unittest`` module.
        - should have a docstring that briefly states the purpose of the test (although doesn't need to be specifically structured).
        - are split into unit and integration test directories. If the test relies on pure python, it should be stored in the 'unit' directory. These tests run very quickly. If it relies on MySQL, PhagesDB, parsing files, creating files and directories, etc. it should be stored in the 'integration' directory. These tests run more slowly.



Schema refactoring
------------------

Any changes made to the structure (schema) of the database (in the form of schema refactoring, schema improvements, and data migration) should be tracked. In order to do this, paired upgrade/downgrade scripts should be created, so that the schema changes can be implemented or reversed if needed.

    1. Determine which aspects of the schema should be changed.

    2. Create a MySQL script that contains the statements needed to make all changes (including incrementing version.SchemaVersion).

    3. In the MySQL command line utility, manually execute each statement on a test database to verify the necessary changes are successful.

    4. Once all statements are constructed, execute the entire MySQL 'upgrade' script at the command line to ensure it works properly::

        > mysql -u root -p <test database> < upgrade_script.sql

    5. Now create a 'downgrade' script to undo the changes. The order of the downgrade statements should be in the reverse order as the upgrade statements. As with the upgrade statements, first test each statement individually in the MySQL command line utility, then test the entire downgrade script at the command line.

    6. It is important that the database schema created when upgrading from an earlier schema version is identical to the database schema created when downgrading from a later schema version. Using a test database, this can be determined with the new paired upgrade/downgrade scripts as follows:

        1. Export the empty schema before upgrade::

            > mysqldump --no-data -u root -p --skip-comments <db_name> > db_schema_before.sql

        2. Run the upgrade script::

            > mysql -u root -p <test database> < upgrade_script.sql

        3. Run the downgrade script::

            > mysql -u root -p <test database> < upgrade_script.sql

        4. Export the empty schema after downgrade::

            > mysqldump --no-data -u root -p --skip-comments <db_name> > db_schema_after.sql

        5. Check the difference between the empty schemas. Other than AUTO-INCREMENT values, there should be no substantial differences::

            > diff db_schema_before.sql db_schema_after.sql

        6. If the conversion round-trip does not produce an identical empty schema, modify the upgrade or downgrade statements accordingly.

    7. Incorporate the upgrade and downgrade statements into the ``pdm_utils`` schema_conversions module so that they can be implemented using the Python package.

    8. In the convert module, edit the CURRENT_VERSION and MAX_VERSION variables accordingly.

    9. Use the convert module to upgrade the primary production database to the new schema version. This will convert the schema and update version.SchemaVersion.

    10. A history of each unique database schema is stored under /misc/schemas/. Create an empty schema of the upgraded database::

        > mysqldump --no-data -u root -p --skip-comments <db_name> > db_schema_<new schema int>.sql

    11. Add the sql file to the schemas directory in the repo.

    12. Update the schema_updates.txt history file with the changes, including a summary of the types of changes implemented.

    13. Generate a schema map and update all sections of the user guide (see below).

        1. Open MySQL Workbench and connect to the server.

        2. Under the Database menu, select Reverse Engineer.

        3. Choose the database of interest.

        4. Manually move table icons so they are intuitively arranged.

        5. Under File, select Export, then select Export as Single Page PDF.

        6. Open the PDF in Preview, and under File, select Export, then select Format JPEG 300 resolution.

        7. Add the JPEG to the repo in the user guide directory.

    14. Update the user guide as needed with information about the new schema:

        - page describing the current database
        - page describing prior schema version schema maps
        - page describing schema version changelog
